{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nvidia_deeplearningexamples_tacotron2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/allhanz/Text_to_speech_engine/blob/master/nvidia_deeplearningexamples_tacotron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sep5MF_9WO-D",
        "colab_type": "text"
      },
      "source": [
        "### This notebook requires a GPU runtime to run.\n",
        "### Please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# Tacotron 2\n",
        "\n",
        "*Author: NVIDIA*\n",
        "\n",
        "**The Tacotron 2 model for generating mel spectrograms from text**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/tacotron2_diagram.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2x-Z5IXVmM",
        "colab_type": "code",
        "outputId": "27466ea7-d3c3-4bad-b3ea-6c9272e52d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 19.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 19.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 17.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 14.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 15.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 15.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 15.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 15.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZSGhjZhWO-H",
        "colab_type": "code",
        "outputId": "9c4ae1c5-cc54-4f34-9bcb-6ee7f83213b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "tacotron2 = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub\n",
            "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/tacotron2pyt_fp32/versions/1/files/nvidia_tacotron2pyt_fp32_20190306.pth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq3R1cp2WO-L",
        "colab_type": "text"
      },
      "source": [
        "will load the Tacotron2 model pre-trained on [LJ Speech dataset](https://keithito.com/LJ-Speech-Dataset/)\n",
        "\n",
        "### Model Description\n",
        "\n",
        "The Tacotron 2 and WaveGlow model form a text-to-speech system that enables user to synthesise a natural sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech.\n",
        "\n",
        "This implementation of Tacotron 2 model differs from the model described in the paper. Our implementation uses Dropout instead of Zoneout to regularize the LSTM layers.\n",
        "\n",
        "### Example\n",
        "\n",
        "In the example below:\n",
        "- pretrained Tacotron2 and Waveglow models are loaded from torch.hub\n",
        "- Tacotron2 generates mel spectrogram given tensor represantation of an input text (\"Hello world, I missed you\")\n",
        "- Waveglow generates sound given the mel spectrogram\n",
        "- the output sound is saved in an 'audio.wav' file\n",
        "\n",
        "To run the example you need some extra python packages installed.\n",
        "These are needed for preprocessing the text and audio, as well as for display and input / output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U8OBKcMWO-M",
        "colab_type": "code",
        "outputId": "622fbf05-a1df-403e-dee0-c797dbda1b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "%%bash\n",
        "pip install numpy scipy librosa unidecode inflect librosa"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.14.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.47.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (45.2.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdr0nluBWO-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io.wavfile import write"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crLEuLjGWO-U",
        "colab_type": "text"
      },
      "source": [
        "Prepare tacotron2 for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBMsiPc0WO-V",
        "colab_type": "code",
        "outputId": "d13829cb-98f2-4324-d173-4b230a365110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tacotron2 = tacotron2.to('cuda')\n",
        "tacotron2.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tacotron2(\n",
              "  (embedding): Embedding(148, 512)\n",
              "  (encoder): Encoder(\n",
              "    (convolutions): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (prenet): Prenet(\n",
              "      (layers): ModuleList(\n",
              "        (0): LinearNorm(\n",
              "          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n",
              "        )\n",
              "        (1): LinearNorm(\n",
              "          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (attention_rnn): LSTMCell(768, 1024)\n",
              "    (attention_layer): Attention(\n",
              "      (query_layer): LinearNorm(\n",
              "        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
              "      )\n",
              "      (memory_layer): LinearNorm(\n",
              "        (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n",
              "      )\n",
              "      (v): LinearNorm(\n",
              "        (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n",
              "      )\n",
              "      (location_layer): LocationLayer(\n",
              "        (location_conv): ConvNorm(\n",
              "          (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n",
              "        )\n",
              "        (location_dense): LinearNorm(\n",
              "          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder_rnn): LSTMCell(1536, 1024, bias=1)\n",
              "    (linear_projection): LinearNorm(\n",
              "      (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n",
              "    )\n",
              "    (gate_layer): LinearNorm(\n",
              "      (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (postnet): Postnet(\n",
              "    (convolutions): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): ConvNorm(\n",
              "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
              "        )\n",
              "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-bsT6bfWO-X",
        "colab_type": "text"
      },
      "source": [
        "Load waveglow from PyTorch Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zZKe_UxWO-Y",
        "colab_type": "code",
        "outputId": "78dc5342-2581-4202-a90f-2cf3f05d9941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow')\n",
        "waveglow = waveglow.remove_weightnorm(waveglow)\n",
        "waveglow = waveglow.to('cuda')\n",
        "waveglow.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub\n",
            "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WaveGlow(\n",
              "  (upsample): ConvTranspose1d(80, 80, kernel_size=(1024,), stride=(256,))\n",
              "  (WN): ModuleList(\n",
              "    (0): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (1): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (2): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (3): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (4): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (5): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (6): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (7): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (8): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (9): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (10): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (11): WN(\n",
              "      (in_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
              "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
              "      )\n",
              "      (res_skip_layers): ModuleList(\n",
              "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (cond_layers): ModuleList(\n",
              "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
              "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "  )\n",
              "  (convinv): ModuleList(\n",
              "    (0): Invertible1x1Conv(\n",
              "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (1): Invertible1x1Conv(\n",
              "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (2): Invertible1x1Conv(\n",
              "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (3): Invertible1x1Conv(\n",
              "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (4): Invertible1x1Conv(\n",
              "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (5): Invertible1x1Conv(\n",
              "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (6): Invertible1x1Conv(\n",
              "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (7): Invertible1x1Conv(\n",
              "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (8): Invertible1x1Conv(\n",
              "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (9): Invertible1x1Conv(\n",
              "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (10): Invertible1x1Conv(\n",
              "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "    (11): Invertible1x1Conv(\n",
              "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vavqc2PSWO-b",
        "colab_type": "text"
      },
      "source": [
        "Now, let's make the model say *\"hello world, I missed you\"*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ajvdqEWO-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"hello world, I missed you\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Zv1AXyWO-g",
        "colab_type": "text"
      },
      "source": [
        "Now chain pre-processing -> tacotron2 -> waveglow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajnbhvh7WO-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessing\n",
        "sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
        "sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
        "\n",
        "# run the models\n",
        "with torch.no_grad():\n",
        "    _, mel, _, _ = tacotron2.infer(sequence)\n",
        "    audio = waveglow.infer(mel)\n",
        "audio_numpy = audio[0].data.cpu().numpy()\n",
        "rate = 22050"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoAu9JPvWO-l",
        "colab_type": "text"
      },
      "source": [
        "You can write it to a file and listen to it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FALoWnxcWO-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "write(\"audio.wav\", rate, audio_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thlajjOiWO-p",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, play it right away in a notebook with IPython widgets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osZJf_6EWO-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Audio\n",
        "Audio(audio_numpy, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HlJjhG5WO-u",
        "colab_type": "text"
      },
      "source": [
        "### Details\n",
        "For detailed information on model input and output, training recipies, inference and performance visit: [github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2) and/or [NGC](https://ngc.nvidia.com/catalog/model-scripts/nvidia:tacotron_2_and_waveglow_for_pytorch)\n",
        "\n",
        "### References\n",
        "\n",
        " - [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)\n",
        " - [WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://arxiv.org/abs/1811.00002)\n",
        " - [Tacotron2 and WaveGlow on NGC](https://ngc.nvidia.com/catalog/model-scripts/nvidia:tacotron_2_and_waveglow_for_pytorch)\n",
        " - [Tacotron2 and Waveglow on github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2)"
      ]
    }
  ]
}